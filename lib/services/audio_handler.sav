import 'dart:async';
import 'dart:io' show Platform;
import 'package:audio_service/audio_service.dart';
import 'package:just_audio/just_audio.dart' as just_audio;
import 'package:audio_session/audio_session.dart';
import 'package:audioplayers/audioplayers.dart' as audioplayers;

// Abstrakte Basisklasse f端r gemeinsame Logik
abstract class AudioHandlerBase extends BaseAudioHandler {
  Future<void> initPlayer();
  Future<void> playMediaItem(MediaItem newMediaItem);
  Future<void> play();
  Future<void> pause();
  Future<void> stop();
  Future<void> seek(Duration position);
  Future<void> skipToNext();
  Future<void> skipToPrevious();
  Future<void> dispose();
}

// Konkrete Implementierung mit plattformspezifischen Overrides
class AudioPlayerHandler extends AudioHandlerBase {
  final _justAudioPlayer = just_audio.AudioPlayer();
  final _audioPlayersPlayer = audioplayers.AudioPlayer();
  bool _useAudioPlayers = false; // F端r Linux
  StreamSubscription? _playbackEventSubscription;
  StreamSubscription? _sequenceStateSubscription;
  StreamSubscription? _audioPlayersStateSubscription;

  AudioPlayerHandler() {
    _determinePlatform();
    initPlayer();
  }

  void _determinePlatform() {
    if (Platform.isLinux) {
      _useAudioPlayers = true;
      print('Verwende audioplayers f端r Linux.');
    } else {
      print('Verwende just_audio f端r ${Platform.operatingSystem}.');
    }
  }

  @override
  Future<void> initPlayer() async {
    try {
      if (_useAudioPlayers) {
        // Linux: Verwende audioplayers
        _audioPlayersStateSubscription =
            _audioPlayersPlayer.onPlayerStateChanged.listen((state) {
          playbackState.add(playbackState.value.copyWith(
            playing: state == audioplayers.PlayerState.playing,
            processingState: state == audioplayers.PlayerState.playing
                ? AudioProcessingState.ready
                : state == audioplayers.PlayerState.paused
                    ? AudioProcessingState.ready
                    : AudioProcessingState.idle,
          ));
        });
        return;
      }

      // Andere Plattformen: Verwende just_audio
      final session = await AudioSession.instance;
      await session.configure(const AudioSessionConfiguration.music());

      _playbackEventSubscription = _justAudioPlayer.playbackEventStream
          .map(_transformEvent)
          .listen((event) {
        playbackState.add(event);
      }, onError: (e) {
        print('Fehler im playbackEventStream: $e');
      });

      _sequenceStateSubscription =
          _justAudioPlayer.sequenceStateStream.listen((event) {
        if (event?.currentSource != null) {
          final bool isRadioStream =
              event.currentSource?.tag.extras?['isRadioStream'] ?? false;
          final MediaItem updatedMediaItem = MediaItem(
            id: event.currentSource!.tag.id,
            title: event.currentSource!.tag.title,
            artist: event.currentSource!.tag.artist,
            artUri: event.currentSource!.tag.artUri,
            duration: event.currentSource?.duration,
            extras: {'isRadioStream': isRadioStream},
          );
          mediaItem.add(updatedMediaItem);
        } else {
          mediaItem.add(null);
        }
      }, onError: (e) {
        print('Fehler im sequenceStateStream: $e');
      });
    } catch (e) {
      print('Fehler bei der Initialisierung des AudioPlayers: $e');
      playbackState.add(playbackState.value.copyWith(
        processingState: AudioProcessingState.error,
      ));
    }
  }

  @override
  Future<void> playMediaItem(MediaItem newMediaItem) async {
    try {
      mediaItem.add(newMediaItem);
      if (_useAudioPlayers) {
        await _audioPlayersPlayer.play(audioplayers.UrlSource(newMediaItem.id));
        return;
      }
      await _justAudioPlayer.setAudioSource(
        just_audio.AudioSource.uri(Uri.parse(newMediaItem.id),
            tag: newMediaItem),
      );
      await _justAudioPlayer.play();
    } catch (e) {
      print('Fehler beim Abspielen des MediaItems: $e');
      playbackState.add(playbackState.value.copyWith(
        processingState: AudioProcessingState.error,
      ));
    }
  }

  @override
  Future<void> play() async {
    try {
      if (_useAudioPlayers) {
        await _audioPlayersPlayer.resume();
        return;
      }
      if (!_justAudioPlayer.playing) {
        if (_justAudioPlayer.audioSource == null) {
          print('Audioquelle nicht initialisiert. Bitte zuerst playMediaItem aufrufen.');
          return;
        }
        await _justAudioPlayer.play();
      }
    } catch (e) {
      print('Fehler beim Abspielen: $e');
    }
  }

  @override
  Future<void> pause() async {
    try {
      if (_useAudioPlayers) {
        await _audioPlayersPlayer.pause();
        return;
      }
      if (_justAudioPlayer.playing) {
        await _justAudioPlayer.pause();
      }
    } catch (e) {
      print('Fehler beim Pausieren: $e');
    }
  }

  @override
  Future<void> stop() async {
    try {
      if (_useAudioPlayers) {
        await _audioPlayersPlayer.stop();
      } else {
        await _justAudioPlayer.stop();
      }
      playbackState.add(playbackState.value.copyWith(
        controls: [],
        playing: false,
        processingState: AudioProcessingState.idle,
      ));
      mediaItem.add(null);
    } catch (e) {
      print('Fehler beim Stoppen: $e');
    }
  }

  @override
  Future<void> seek(Duration position) async {
    try {
      if (_useAudioPlayers) {
        await _audioPlayersPlayer.seek(position);
        return;
      }
      await _justAudioPlayer.seek(position);
    } catch (e) {
      print('Fehler beim Seek: $e');
    }
  }

  @override
  Future<void> skipToNext() async {
    playbackState.add(playbackState.value.copyWith(
      controls: [MediaControl.skipToNext],
      playing: true,
      processingState: AudioProcessingState.loading,
    ));
    await super.skipToNext();
  }

  @override
  Future<void> skipToPrevious() async {
    playbackState.add(playbackState.value.copyWith(
      controls: [MediaControl.skipToPrevious],
      playing: true,
      processingState: AudioProcessingState.loading,
    ));
    await super.skipToPrevious();
  }

  @override
  Future<void> dispose() async {
    try {
      if (_useAudioPlayers) {
        await _audioPlayersStateSubscription?.cancel();
        await _audioPlayersPlayer.stop();
        await _audioPlayersPlayer.dispose();
      } else {
        await _playbackEventSubscription?.cancel();
        await _sequenceStateSubscription?.cancel();
        await _justAudioPlayer.stop();
        await _justAudioPlayer.dispose();
      }
      await stop();
    } catch (e) {
      print('Fehler beim Entsorgen des AudioPlayerHandlers: $e');
    }
  }

  PlaybackState _transformEvent(just_audio.PlaybackEvent event) {
    return PlaybackState(
      controls: [
        if (_justAudioPlayer.playing) MediaControl.pause else MediaControl.play,
        if (_justAudioPlayer.hasPrevious) MediaControl.skipToPrevious,
        if (_justAudioPlayer.hasNext) MediaControl.skipToNext,
        MediaControl.stop,
      ],
      systemActions: const {
        MediaAction.seek,
        MediaAction.play,
        MediaAction.pause,
        MediaAction.stop,
        MediaAction.skipToNext,
        MediaAction.skipToPrevious,
      },
      androidCompactActionIndices: const [0, 1, 3],
      processingState: {
        just_audio.ProcessingState.idle: AudioProcessingState.idle,
        just_audio.ProcessingState.loading: AudioProcessingState.loading,
        just_audio.ProcessingState.buffering: AudioProcessingState.buffering,
        just_audio.ProcessingState.ready: AudioProcessingState.ready,
        just_audio.ProcessingState.completed: AudioProcessingState.completed,
      }[_justAudioPlayer.processingState]!,
      playing: _justAudioPlayer.playing,
      updatePosition: _justAudioPlayer.position,
      bufferedPosition: _justAudioPlayer.bufferedPosition,
      speed: _justAudioPlayer.speed,
      queueIndex: _justAudioPlayer.currentIndex,
    );
  }
}
